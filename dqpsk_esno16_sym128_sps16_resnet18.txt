Namespace(arch='resnet18', cuda='3', root='D:/dqpsk_awgn_sym128_sps16_esno16.dat')
ResNet(
  (conv1): Conv1d(2, 64, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (fc): Linear(in_features=512, out_features=2, bias=True)
)
loading data
  epoch    accuracy    train_loss    valid_loss    cp       dur
-------  ----------  ------------  ------------  ----  --------
      1      0.8960        0.5841        0.2629     +  128.5668
      2      0.9578        0.1586        0.1075     +  126.8415
      3      0.9708        0.0861        0.0752     +  127.1377
      4      0.9769        0.0597        0.0601     +  127.4349
      5      0.9809        0.0450        0.0495     +  127.4429
      6      0.9835        0.0362        0.0447     +  127.5850
      7      0.9852        0.0289        0.0404     +  127.4380
      8      0.9858        0.0242        0.0385     +  127.6311
      9      0.9863        0.0200        0.0360     +  127.5110
     10      0.9873        0.0168        0.0352     +  127.2338
     11      0.9876        0.0140        0.0344     +  127.5700
     12      0.9873        0.0118        0.0357        127.3719
     13      0.9879        0.0099        0.0334     +  127.2438
     14      0.9879        0.0079        0.0334     +  127.4799
     15      0.9881        0.0069        0.0337        127.3478
     16      0.9885        0.0061        0.0334        127.5450
     17      0.9881        0.0050        0.0337        121.8348
     18      0.9883        0.0042        0.0340        121.3204
Re-initializing optimizer because the following parameters were re-set: lr.
     19      0.9886        0.0039        0.0338        121.7777
     20      0.9883        0.0032        0.0338        121.6256
     21      0.9887        0.0029        0.0334     +  121.6265
     22      0.9887        0.0030        0.0333     +  121.5435
     23      0.9889        0.0027        0.0333     +  120.8350
     24      0.9888        0.0026        0.0333        120.2065
     25      0.9887        0.0029        0.0334        120.4657
     26      0.9887        0.0028        0.0335        120.3617
     27      0.9888        0.0025        0.0336        120.9871
Re-initializing optimizer because the following parameters were re-set: lr.
     28      0.9888        0.0025        0.0333        121.0341
     29      0.9887        0.0026        0.0334        120.9030
     30      0.9888        0.0025        0.0334        121.0991
     31      0.9887        0.0026        0.0333        120.9751
     32      0.9885        0.0025        0.0335        121.0902
     33      0.9888        0.0025        0.0334        120.9251
     34      0.9886        0.0027        0.0334        121.2823
     35      0.9887        0.0027        0.0333        121.2393
     36      0.9885        0.0025        0.0340        121.1252
     37      0.9887        0.0027        0.0335        120.9982
     38      0.9887        0.0024        0.0334        122.2260
     39      0.9888        0.0025        0.0336        122.5542
     40      0.9888        0.0026        0.0333        121.9138
     41      0.9885        0.0025        0.0336        121.7677
     42      0.9883        0.0027        0.0346        123.0036
Stopping since valid_loss has not improved in the last 20 epochs.
Best Model State Restored
Best Confusion Matrix:
 [[99  1]
 [ 1 99]]
